{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  Federated Learning Training Plan: Create Plan\n",
    "\n",
    "### Note: This notebook is inspired from [here](https://github.com/OpenMined/PySyft/blob/master/examples/experimental/FL%20Training%20Plan/Create%20Plan.ipynb)\n",
    "\n",
    "Let's try to make protobuf-serializable Training Plan and Model that work after deserializing :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f514174e610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import syft as sy\n",
    "import torch as th\n",
    "from torch import jit\n",
    "from torch import nn\n",
    "from syft.serde import protobuf\n",
    "import os\n",
    "from syft.execution.state import State\n",
    "from syft.execution.placeholder import PlaceHolder\n",
    "\n",
    "\n",
    "\n",
    "sy.make_hook(globals())\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None\n",
    "th.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This utility function will serialize any object to protobuf binary and save to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def serialize_to_bin_pb(worker, obj, filename):\n",
    "    pb = protobuf.serde._bufferize(worker, obj)\n",
    "    bin = pb.SerializeToString()\n",
    "    print(\"Writing %s to %s/%s\" % (obj.__class__.__name__, os.getcwd(), filename))\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(bin)\n",
    "\n",
    "\n",
    "def set_model_params(module, params_list, start_param_idx=0):\n",
    "    \"\"\" Set params list into model recursively\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "    for name, param in module._parameters.items():\n",
    "        module._parameters[name] = params_list[param_idx]\n",
    "        param_idx += 1\n",
    "\n",
    "    for name, child in module._modules.items():\n",
    "        if child is not None:\n",
    "            param_idx += set_model_params(child, params_list, param_idx)\n",
    "\n",
    "    return param_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "Model defined in tensorflow:\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "- Embedding dimension is 50\n",
    "- Max sentence length is 120\n",
    "- And after the embedding layer, we also have a flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note: The emedding layer, is missing, as currently we are using a non-trainable\n",
    "# embedding layer.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(120*50 , 120)\n",
    "        self.fc2 = nn.Linear(120 , 2)   ##### Num Classes = 2, positive or negative sentiment.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Define Training Plan\n",
    "### Loss function \n",
    "Batch size needs to be passed because otherwise `target.shape[0]` is not traced inside Plan yet (Issue [#3554](https://github.com/OpenMined/PySyft/issues/3554)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax.\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    # numstable logsoftmax\n",
    "    norm_logits = logits - logits.max()\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    # NLL, reduction = mean\n",
    "    return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimization function\n",
    " \n",
    "Just updates weights with grad*lr.\n",
    "\n",
    "Note: can't do inplace update because of Autograd/Plan tracing specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    return param - kwargs['lr'] * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training Plan procedure\n",
    "\n",
    "We define a routine that will take one batch of training data, and model parameters,\n",
    "and will update model parameters to optimize them for given loss function using SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@sy.func2plan()\n",
    "def training_plan(X, y, batch_size, lr, model_params):\n",
    "    # inject params into model\n",
    "    set_model_params(model, model_params)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model.forward(X)\n",
    "    \n",
    "    # loss\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "    \n",
    "    # backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # step\n",
    "    updated_params = [\n",
    "       naive_sgd(param, lr=lr)\n",
    "       for param in model_params\n",
    "    ]\n",
    "    \n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum().float() / batch_size\n",
    "\n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        *model_params\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's build this procedure into the Plan that we can serialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy input parameters to make the trace\n",
    "model_params = list(model.parameters())\n",
    "X = th.randn(3, 50*120)\n",
    "\n",
    "NEGATIVE = 0\n",
    "POSITIVE = 1\n",
    "\n",
    "y = nn.functional.one_hot(th.tensor([NEGATIVE, NEGATIVE, POSITIVE]), 2)   # One hot vectors of dimension 2\n",
    "lr = th.tensor([0.01])\n",
    "batch_size = th.tensor([3.0])\n",
    "\n",
    "_ = training_plan.build(X, y, batch_size, lr, model_params, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = model.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits.child.child.child.child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dissected_softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "#     \"\"\" Calculates softmax.\n",
    "#         Args:\n",
    "#             * logits: (NxC) outputs of dense layer\n",
    "#             * targets: (NxC) one-hot encoded labels\n",
    "#             * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "#     \"\"\"\n",
    "#     # numstable logsoftmax\n",
    "#     norm_logits = logits - logits.max()\n",
    "#     print(norm_logits)\n",
    "#     log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "#     print(norm_logits.sum(dim=1, keepdim=True))  # Removed exp() and log()\n",
    "#     # NLL, reduction = mean\n",
    "#     print(log_probs)\n",
    "#     print(targets)\n",
    "#     print(targets * log_probs)\n",
    "#     return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's look inside the Syft Plan and print out the list of operations recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def training_plan(arg_1, arg_2, arg_3, arg_4, out_3, out_4, out_5, out_6):\n",
      "    2 = arg_1.dim()\n",
      "    var_0 = out_3.t()\n",
      "    var_1 = arg_1.matmul(var_0)\n",
      "    var_2 = out_4.add(var_1)\n",
      "    var_3 = var_2.relu()\n",
      "    2 = var_3.dim()\n",
      "    var_4 = out_5.t()\n",
      "    var_5 = var_3.matmul(var_4)\n",
      "    var_6 = out_6.add(var_5)\n",
      "    var_7 = var_6.max()\n",
      "    var_8 = var_6.sub(var_7)\n",
      "    var_9 = var_8.exp()\n",
      "    var_10 = var_9.sum(dim=1, keepdim=True)\n",
      "    var_11 = var_10.log()\n",
      "    var_12 = var_8.sub(var_11)\n",
      "    var_13 = arg_2.mul(var_12)\n",
      "    var_14 = var_13.sum()\n",
      "    var_15 = var_14.neg()\n",
      "    out_1 = var_15.div(arg_3)\n",
      "    var_16 = out_1.mul(0)\n",
      "    var_17 = var_16.add(1)\n",
      "    var_18 = var_17.div(arg_3)\n",
      "    var_19 = var_18.mul(-1)\n",
      "    var_20 = var_13.mul(0)\n",
      "    var_21 = var_20.add(1)\n",
      "    var_22 = var_21.mul(var_19)\n",
      "    var_23 = var_22.mul(var_12)\n",
      "    var_24 = var_22.mul(arg_2)\n",
      "    var_25 = var_23.copy()\n",
      "    var_26 = var_24.add(0)\n",
      "    var_27 = var_24.mul(-1)\n",
      "    var_28 = var_27.sum(dim=[1], keepdim=True)\n",
      "    var_29 = var_26.add(0)\n",
      "    var_30 = var_26.mul(-1)\n",
      "    var_31 = var_30.sum(dim=[1, 0])\n",
      "    var_32 = var_29.add(0)\n",
      "    var_33 = var_29.add(0)\n",
      "    var_34 = var_32.sum(dim=[0])\n",
      "    var_35 = var_34.copy()\n",
      "    var_36 = var_4.t()\n",
      "    var_37 = var_33.matmul(var_36)\n",
      "    var_38 = var_3.t()\n",
      "    var_39 = var_38.matmul(var_33)\n",
      "    var_40 = var_2.mul(0)\n",
      "    var_41 = var_2.__gt__(var_40)\n",
      "    var_42 = var_41.mul(var_37)\n",
      "    var_43 = var_42.add(0)\n",
      "    var_44 = var_42.add(0)\n",
      "    var_45 = var_43.sum(dim=[0])\n",
      "    var_46 = var_45.copy()\n",
      "    var_47 = var_0.t()\n",
      "    var_48 = var_44.matmul(var_47)\n",
      "    var_49 = arg_1.t()\n",
      "    var_50 = var_49.matmul(var_44)\n",
      "    var_51 = var_48.copy()\n",
      "    var_52 = var_50.t()\n",
      "    var_53 = var_52.copy()\n",
      "    var_54 = var_39.t()\n",
      "    var_55 = var_54.copy()\n",
      "    var_56 = var_31.copy()\n",
      "    var_57 = var_10.__rtruediv__(1)\n",
      "    var_58 = var_28.mul(var_57)\n",
      "    var_59 = var_9.mul(0)\n",
      "    var_60 = var_59.add(1)\n",
      "    var_61 = var_60.mul(var_58)\n",
      "    var_62 = var_8.exp()\n",
      "    var_63 = var_61.mul(var_62)\n",
      "    var_64 = var_63.add(0)\n",
      "    var_65 = var_63.mul(-1)\n",
      "    var_66 = var_65.sum(dim=[1, 0])\n",
      "    var_67 = var_64.add(0)\n",
      "    var_68 = var_64.add(0)\n",
      "    var_69 = var_67.sum(dim=[0])\n",
      "    var_70 = var_35.add_(var_69)\n",
      "    var_71 = var_4.t()\n",
      "    var_72 = var_68.matmul(var_71)\n",
      "    var_73 = var_3.t()\n",
      "    var_74 = var_73.matmul(var_68)\n",
      "    var_75 = var_2.mul(0)\n",
      "    var_76 = var_2.__gt__(var_75)\n",
      "    var_77 = var_76.mul(var_72)\n",
      "    var_78 = var_77.add(0)\n",
      "    var_79 = var_77.add(0)\n",
      "    var_80 = var_78.sum(dim=[0])\n",
      "    var_81 = var_46.add_(var_80)\n",
      "    var_82 = var_0.t()\n",
      "    var_83 = var_79.matmul(var_82)\n",
      "    var_84 = arg_1.t()\n",
      "    var_85 = var_84.matmul(var_79)\n",
      "    var_86 = var_51.add_(var_83)\n",
      "    var_87 = var_85.t()\n",
      "    var_88 = var_53.add_(var_87)\n",
      "    var_89 = var_74.t()\n",
      "    var_90 = var_55.add_(var_89)\n",
      "    var_91 = var_56.add_(var_66)\n",
      "    var_92 = arg_4.mul(var_53)\n",
      "    var_93 = out_3.sub(var_92)\n",
      "    var_94 = arg_4.mul(var_46)\n",
      "    var_95 = out_4.sub(var_94)\n",
      "    var_96 = arg_4.mul(var_55)\n",
      "    var_97 = out_5.sub(var_96)\n",
      "    var_98 = arg_4.mul(var_35)\n",
      "    var_99 = out_6.sub(var_98)\n",
      "    var_100 = torch.argmax(var_6, dim=1)\n",
      "    var_101 = torch.argmax(arg_2, dim=1)\n",
      "    var_102 = var_100.eq(var_101)\n",
      "    var_103 = var_102.sum()\n",
      "    var_104 = var_103.float()\n",
      "    out_2 = var_104.div(arg_3)\n",
      "    return out_1, out_2, out_3, out_4, out_5, out_6\n"
     ]
    }
   ],
   "source": [
    "print(training_plan.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plan should be automatically translated to torchscript, too.\n",
    "Let's examine torchscript code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def <Plan training_plan id:88661284708 owner:me built>\n",
      "(argument_0: Tensor,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: List[Tensor]) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0, _1, _2, _3, = argument_4\n",
      "  _4 = torch.add(_1, torch.matmul(argument_0, torch.t(_0)), alpha=1)\n",
      "  _5 = torch.matmul(torch.relu(_4), torch.t(_2))\n",
      "  _6 = torch.add(_3, _5, alpha=1)\n",
      "  _7 = torch.sub(_6, torch.max(_6), alpha=1)\n",
      "  _8 = torch.sum(torch.exp(_7), [1], True, dtype=None)\n",
      "  _9 = torch.mul(argument_1, torch.sub(_7, torch.log(_8), alpha=1))\n",
      "  _10 = torch.eq(torch.argmax(_6, 1, False), torch.argmax(argument_1, 1, False))\n",
      "  _11 = torch.to(torch.sum(_10, dtype=None), 6, False, False, None)\n",
      "  _12 = torch.div(torch.neg(torch.sum(_9, dtype=None)), argument_2)\n",
      "  _13 = (_12, torch.div(_11, argument_2), _0, _1, _2, _3)\n",
      "  return _13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_plan.torchscript.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Serialize!\n",
    "\n",
    "Now it's time to serialize model params and plans to protobuf and save them for further usage:\n",
    " * In \"Execute Plan\" notebook, we load and execute these plans & model, from Python.\n",
    " * In \"Host Plan\" notebook, we send these plans & model to PyGrid, so it can be executed from other worker (e.g. syft.js).\n",
    "\n",
    "**NOTE:**\n",
    " * We don't serialize full Model, only weights. How the Model is serialized is TBD.\n",
    "   State is suitable protobuf class to wrap list of Model params tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Plan to /home/sachin/Desktop/Cryptly_ws/Cryptly/Grid/cryptly_training_plan.pb\n",
      "Writing State to /home/sachin/Desktop/Cryptly_ws/Cryptly/Grid/cryptly_model_params.pb\n"
     ]
    }
   ],
   "source": [
    "serialize_to_bin_pb(hook.local_worker, training_plan, \"cryptly_training_plan.pb\")\n",
    "\n",
    "# wrap weights in State to serialize\n",
    "model_params_state = State(\n",
    "    state_placeholders=[\n",
    "        PlaceHolder().instantiate(param)\n",
    "        for param in model_params\n",
    "    ]\n",
    ")\n",
    "\n",
    "serialize_to_bin_pb(hook.local_worker, model_params_state, \"cryptly_model_params.pb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('openmined': conda)",
   "language": "python",
   "name": "python361064bitopenminedconda7d626f6923e74ad6af0109078ac21f5f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
