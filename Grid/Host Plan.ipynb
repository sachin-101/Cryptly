{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning Training Plan: Host Plan & Model\n",
    "\n",
    "### Note: This notebook is inspired from [here](https://github.com/OpenMined/PySyft/blob/master/examples/experimental/FL%20Training%20Plan/Host%20Plan.ipynb)\n",
    "\n",
    "Here we load Plan and Model params created earlier in \"Create Plan\" notebook\n",
    "and host them on PyGrid.\n",
    "\n",
    "After that it should be possible to run FL worker using\n",
    "SwiftSyft, KotlinSyft, syft.js, or FL python worker\n",
    "and train the hosted model using local worker's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import websockets\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "import syft as sy\n",
    "from syft.grid.grid_client import GridClient\n",
    "from syft.serde import protobuf\n",
    "from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.execution.v1.state_pb2 import State as StatePB\n",
    "\n",
    "sy.make_hook(globals())\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "async def sendWsMessage(data):\n",
    "    async with websockets.connect('ws://' + gatewayWsUrl) as websocket:\n",
    "        await websocket.send(json.dumps(data))\n",
    "        message = await websocket.recv()\n",
    "        return json.loads(message)\n",
    "\n",
    "def deserializeFromBin(worker, filename, pb):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        bin = f.read()\n",
    "    pb.ParseFromString(bin)\n",
    "    return protobuf.serde._unbufferize(worker, pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4a: Host in PyGrid\n",
    "\n",
    "Here we load \"ops list\" Plan.\n",
    "PyGrid should translate it to other types (e.g. torchscript) automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Load files with protobuf created in \"Create Plan\" notebook.\n",
    "training_plan = deserializeFromBin(hook.local_worker, \"cryptly_training_plan.pb\", PlanPB())\n",
    "model_params_state = deserializeFromBin(hook.local_worker, \"cryptly_model_params.pb\", StatePB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Follow PyGrid README.md to build `openmined/grid-gateway` image from the latest `dev` branch \n",
    "and spin up PyGrid using `docker-compose up --build`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Default gateway address when running locally \n",
    "gatewayWsUrl = \"127.0.0.1:5001\"\n",
    "grid = GridClient(id=\"test\", address=gatewayWsUrl, secure=False)\n",
    "grid.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define name, version, configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These name/version you use in worker\n",
    "name = \"Cryptly\"\n",
    "version = \"1.0.0\"\n",
    "client_config = {\n",
    "            \"name\": name,  \n",
    "            \"version\": version,\n",
    "            \"batch_size\": 1,  ################## Change\n",
    "            \"lr\": 0.005,\n",
    "            \"max_updates\": 100  # custom syft.js option that limits number of training loops per worker\n",
    "        }\n",
    "\n",
    "server_config = {\n",
    "            \"min_workers\": 3,  # temporarily this plays role \"min # of worker's diffs\" for triggering cycle end event\n",
    "            \"max_workers\": 3,\n",
    "            \"pool_selection\": \"random\",\n",
    "            \"num_cycles\": 5,\n",
    "            \"do_not_reuse_workers_until_cycle\": 4,\n",
    "            \"cycle_length\": 28800,\n",
    "            \"minimum_upload_speed\": 0,\n",
    "            \"minimum_download_speed\": 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Shoot!\n",
    "\n",
    "If everything's good, success is returned.\n",
    "If the name/version already exists in PyGrid, change them above or cleanup PyGrid db by re-creating docker containers (e.g. `docker-compose up --force-recreate`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host response: {'type': 'federated/host-training', 'data': {'status': 'success'}}\n"
     ]
    }
   ],
   "source": [
    "response = grid.host_federated_training(\n",
    "    model=model_params_state,\n",
    "    client_plans={'training_plan': training_plan},\n",
    "    client_protocols={},\n",
    "    server_averaging_plan=None,\n",
    "    client_config=client_config,\n",
    "    server_config=server_config\n",
    ")\n",
    "\n",
    "print(\"Host response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's double-check that data is loaded by requesting a cycle.\n",
    "\n",
    "(Request is made directly, will be methods on grid client in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth response:  {\n",
      "  \"type\": \"federated/authenticate\",\n",
      "  \"data\": {\n",
      "    \"status\": \"success\",\n",
      "    \"worker_id\": \"3fc8bf58-f7c7-45a8-91b7-bf4a95eba306\"\n",
      "  }\n",
      "}\n",
      "Cycle response: {\n",
      "  \"type\": \"federated/cycle-request\",\n",
      "  \"data\": {\n",
      "    \"status\": \"accepted\",\n",
      "    \"request_key\": \"291b6118ff361d496d349bea4ff8cd78244480adac5b4a4c07a916889bbeb0dd\",\n",
      "    \"version\": \"1.0.0\",\n",
      "    \"model\": \"Cryptly\",\n",
      "    \"plans\": {\n",
      "      \"training_plan\": 4\n",
      "    },\n",
      "    \"protocols\": {},\n",
      "    \"client_config\": {\n",
      "      \"name\": \"Cryptly\",\n",
      "      \"version\": \"1.0.0\",\n",
      "      \"batch_size\": 1,\n",
      "      \"lr\": 0.005,\n",
      "      \"max_updates\": 100\n",
      "    },\n",
      "    \"model_id\": 2\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "auth_request = {\n",
    "    \"type\": \"federated/authenticate\",\n",
    "    \"data\": {}\n",
    "}\n",
    "auth_response = await sendWsMessage(auth_request)\n",
    "print('Auth response: ', json.dumps(auth_response, indent=2))\n",
    "\n",
    "cycle_request = {\n",
    "    \"type\": \"federated/cycle-request\",\n",
    "    \"data\": {\n",
    "        \"worker_id\": auth_response['data']['worker_id'],\n",
    "        \"model\": name,\n",
    "        \"version\": version,\n",
    "        \"ping\": 1,\n",
    "        \"download\": 10000,\n",
    "        \"upload\": 10000,\n",
    "    }\n",
    "}\n",
    "cycle_response = await sendWsMessage(cycle_request)\n",
    "print('Cycle response:', json.dumps(cycle_response, indent=2))\n",
    "\n",
    "worker_id = auth_response['data']['worker_id']\n",
    "request_key = cycle_response['data']['request_key']\n",
    "model_id = cycle_response['data']['model_id'] \n",
    "training_plan_id = cycle_response['data']['plans']['training_plan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's download model and plan (both versions) and check they are actually workable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params shapes: [torch.Size([120, 6000]), torch.Size([120]), torch.Size([2, 120]), torch.Size([2])]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-model?worker_id={worker_id}&request_key={request_key}&model_id={model_id}\")\n",
    "model_data = req.content\n",
    "pb = StatePB()\n",
    "pb.ParseFromString(req.content)\n",
    "model_params_downloaded = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(\"Params shapes:\", [p.shape for p in model_params_downloaded.tensors()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def training_plan(arg_1, arg_2, arg_3, arg_4, out_3, out_4, out_5, out_6):\n",
      "    2 = arg_1.dim()\n",
      "    var_0 = out_3.t()\n",
      "    var_1 = arg_1.matmul(var_0)\n",
      "    var_2 = out_4.add(var_1)\n",
      "    var_3 = var_2.relu()\n",
      "    2 = var_3.dim()\n",
      "    var_4 = out_5.t()\n",
      "    var_5 = var_3.matmul(var_4)\n",
      "    var_6 = out_6.add(var_5)\n",
      "    var_7 = var_6.max()\n",
      "    var_8 = var_6.sub(var_7)\n",
      "    var_9 = var_8.exp()\n",
      "    var_10 = var_9.sum(dim=1, keepdim=True)\n",
      "    var_11 = var_10.log()\n",
      "    var_12 = var_8.sub(var_11)\n",
      "    var_13 = arg_2.mul(var_12)\n",
      "    var_14 = var_13.sum()\n",
      "    var_15 = var_14.neg()\n",
      "    out_1 = var_15.div(arg_3)\n",
      "    var_16 = out_1.mul(0)\n",
      "    var_17 = var_16.add(1)\n",
      "    var_18 = var_17.div(arg_3)\n",
      "    var_19 = var_18.mul(-1)\n",
      "    var_20 = var_13.mul(0)\n",
      "    var_21 = var_20.add(1)\n",
      "    var_22 = var_21.mul(var_19)\n",
      "    var_23 = var_22.mul(var_12)\n",
      "    var_24 = var_22.mul(arg_2)\n",
      "    var_25 = var_23.copy()\n",
      "    var_26 = var_24.add(0)\n",
      "    var_27 = var_24.mul(-1)\n",
      "    var_28 = var_27.sum(dim=[1], keepdim=True)\n",
      "    var_29 = var_26.add(0)\n",
      "    var_30 = var_26.mul(-1)\n",
      "    var_31 = var_30.sum(dim=[1, 0])\n",
      "    var_32 = var_29.add(0)\n",
      "    var_33 = var_29.add(0)\n",
      "    var_34 = var_32.sum(dim=[0])\n",
      "    var_35 = var_34.copy()\n",
      "    var_36 = var_4.t()\n",
      "    var_37 = var_33.matmul(var_36)\n",
      "    var_38 = var_3.t()\n",
      "    var_39 = var_38.matmul(var_33)\n",
      "    var_40 = var_2.mul(0)\n",
      "    var_41 = var_2.__gt__(var_40)\n",
      "    var_42 = var_41.mul(var_37)\n",
      "    var_43 = var_42.add(0)\n",
      "    var_44 = var_42.add(0)\n",
      "    var_45 = var_43.sum(dim=[0])\n",
      "    var_46 = var_45.copy()\n",
      "    var_47 = var_0.t()\n",
      "    var_48 = var_44.matmul(var_47)\n",
      "    var_49 = arg_1.t()\n",
      "    var_50 = var_49.matmul(var_44)\n",
      "    var_51 = var_48.copy()\n",
      "    var_52 = var_50.t()\n",
      "    var_53 = var_52.copy()\n",
      "    var_54 = var_39.t()\n",
      "    var_55 = var_54.copy()\n",
      "    var_56 = var_31.copy()\n",
      "    var_57 = var_10.__rtruediv__(1)\n",
      "    var_58 = var_28.mul(var_57)\n",
      "    var_59 = var_9.mul(0)\n",
      "    var_60 = var_59.add(1)\n",
      "    var_61 = var_60.mul(var_58)\n",
      "    var_62 = var_8.exp()\n",
      "    var_63 = var_61.mul(var_62)\n",
      "    var_64 = var_63.add(0)\n",
      "    var_65 = var_63.mul(-1)\n",
      "    var_66 = var_65.sum(dim=[1, 0])\n",
      "    var_67 = var_64.add(0)\n",
      "    var_68 = var_64.add(0)\n",
      "    var_69 = var_67.sum(dim=[0])\n",
      "    var_70 = var_35.add_(var_69)\n",
      "    var_71 = var_4.t()\n",
      "    var_72 = var_68.matmul(var_71)\n",
      "    var_73 = var_3.t()\n",
      "    var_74 = var_73.matmul(var_68)\n",
      "    var_75 = var_2.mul(0)\n",
      "    var_76 = var_2.__gt__(var_75)\n",
      "    var_77 = var_76.mul(var_72)\n",
      "    var_78 = var_77.add(0)\n",
      "    var_79 = var_77.add(0)\n",
      "    var_80 = var_78.sum(dim=[0])\n",
      "    var_81 = var_46.add_(var_80)\n",
      "    var_82 = var_0.t()\n",
      "    var_83 = var_79.matmul(var_82)\n",
      "    var_84 = arg_1.t()\n",
      "    var_85 = var_84.matmul(var_79)\n",
      "    var_86 = var_51.add_(var_83)\n",
      "    var_87 = var_85.t()\n",
      "    var_88 = var_53.add_(var_87)\n",
      "    var_89 = var_74.t()\n",
      "    var_90 = var_55.add_(var_89)\n",
      "    var_91 = var_56.add_(var_66)\n",
      "    var_92 = arg_4.mul(var_53)\n",
      "    var_93 = out_3.sub(var_92)\n",
      "    var_94 = arg_4.mul(var_46)\n",
      "    var_95 = out_4.sub(var_94)\n",
      "    var_96 = arg_4.mul(var_55)\n",
      "    var_97 = out_5.sub(var_96)\n",
      "    var_98 = arg_4.mul(var_35)\n",
      "    var_99 = out_6.sub(var_98)\n",
      "    var_100 = torch.argmax(var_6, dim=1)\n",
      "    var_101 = torch.argmax(arg_2, dim=1)\n",
      "    var_102 = var_100.eq(var_101)\n",
      "    var_103 = var_102.sum()\n",
      "    var_104 = var_103.float()\n",
      "    out_2 = var_104.div(arg_3)\n",
      "    return out_1, out_2, out_3, out_4, out_5, out_6\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Plan \"list of ops\"\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-plan?worker_id={worker_id}&request_key={request_key}&plan_id={training_plan_id}&receive_operations_as=list\")\n",
    "pb = PlanPB()\n",
    "pb.ParseFromString(req.content)\n",
    "plan_ops = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(plan_ops.code)\n",
    "print(plan_ops.torchscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def training_plan(arg_1, arg_2, arg_3, arg_4, out_3, out_4, out_5, out_6):\n",
      "    return out_1, out_2, out_3, out_4, out_5, out_6\n",
      "def forward(self,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: Tensor,\n",
      "    argument_5: List[Tensor]) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0, _1, _2, _3, = argument_5\n",
      "  _4 = torch.add(_1, torch.matmul(argument_1, torch.t(_0)), alpha=1)\n",
      "  _5 = torch.matmul(torch.relu(_4), torch.t(_2))\n",
      "  _6 = torch.add(_3, _5, alpha=1)\n",
      "  _7 = torch.sub(_6, torch.max(_6), alpha=1)\n",
      "  _8 = torch.sum(torch.exp(_7), [1], True, dtype=None)\n",
      "  _9 = torch.mul(argument_2, torch.sub(_7, torch.log(_8), alpha=1))\n",
      "  _10 = torch.sum(_9, dtype=None)\n",
      "  _11 = torch.eq(torch.argmax(_6, 1, False), torch.argmax(argument_2, 1, False))\n",
      "  _12 = torch.to(torch.sum(_11, dtype=None), 6, False, False, None)\n",
      "  _13 = (torch.div(torch.neg(_10), argument_3), torch.div(_12, argument_3), _0, _1, _2, _3)\n",
      "  return _13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plan \"torchscript\"\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-plan?worker_id={worker_id}&request_key={request_key}&plan_id={training_plan_id}&receive_operations_as=torchscript\")\n",
    "pb = PlanPB()\n",
    "pb.ParseFromString(req.content)\n",
    "plan_ts = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(plan_ts.code)\n",
    "print(plan_ts.torchscript.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 5a: Train\n",
    "\n",
    "To train hosted model, use one of the existing FL workers:\n",
    " * Python FL Client: see \"[Execute Plan with Python FL Client](Execute%20Plan%20with%20Python%20FL%20Client.ipynb)\" notebook that\n",
    "has example of using python FL worker.\n",
    " * [SwiftSyft](https://github.com/OpenMined/SwiftSyft)\n",
    " * [KotlinSyft](https://github.com/OpenMined/KotlinSyft)\n",
    " * [syft.js](https://github.com/OpenMined/syft.js)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('openmined': conda)",
   "language": "python",
   "name": "python361064bitopenminedconda7d626f6923e74ad6af0109078ac21f5f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
